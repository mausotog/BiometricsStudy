%!TEX root = bioPrediction_main.tex
%\input{bp_results_1}
%%\input{bp_results_2}

\section{Analysis and Results}

\begin{table*}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{rq1performance.pdf}
  \caption{Results of predictions using the individual models. The distribution columns show a bar chart of the response distribution (negative/positive) for each of the three variables. The baseline row represents the averaged results of our baesline classifier. The general row shows the averaged results of our models trained on all participants.}\label{tab:accuracy}%\todo{revise caption}}
  \vspace*{-4mm}
\end{table*}

To evaluate the efficacy of continuously predicting a knowledge worker's stress, focus, and awakeness in the workplace, we trained and tested machine learning classifiers using a leave-one-out cross validation. For prediction, we used the features extracted from the collected data as the input data, and binarized the participants' self-reported responses on stress, focus, and awakeness into two classes each (e.g., 'stressed' and 'not stressed') to use as output measures.

\subsection{Predicting Stress, Focus \& Awakeness}
% random forest best
\label{secOverallAccuracy}
As a first step, we compared multiple classifiers using the popular machine learning library scikit-learn~\cite{pedregosa11} and performing a grid search analysis to determine the optimal hyperparameters for each classifier. Our analysis showed that random forest outperforms all other classifiers, including Na\"ive Bayes, decision trees, support vector machine, random forest, and a multilayer perceptron neural network. The optimal values for random forest and the three output measures are listed in Table \ref{tab:hyperparams}. For the remainder of this paper, we will be referring to random forest classifiers trained with these hyperparameters.%\\[-0.1cm]
% for stress they were (minimum samples for split = 4, # of estimators = 100, max features = 0.5, k=300), for focus they were (minimum samples for split = 4, # of estimators = 50, max features = 0.5, k=200), and for awakeness they were (minimum samples for split = 4, # of estimators = 100, max features = 0.25, k=800)
\begin{table}[h]
	\begin{centering}
	\small\addtolength{\tabcolsep}{-1pt}
    \begin{tabular}{llll}
      \hline
      Variable & K & \# Estimators & Minimum Samples Split \\
      \hline
      Stress & 300 & 100 & 4\\
      Focus & 200 & 50 & 4\\
      Awakeness & 800 & 100 & 4\\
      \hline
    \end{tabular}
    \caption{The hyperparameters selected by grid search analysis to tune our random forest models. K refers to the number of features selected.}    \label{tab:hyperparams}
    \end{centering}
\end{table}



\noindent\textit{Results of Individual Classifiers}\\
Since peoples' experience of stress, focus, and awakeness (as well as their physiological manifestations) can vary a lot (e.g.,~\cite{Hernandez11}), we first trained individual classifiers for each participant (rather than a general one for all participants). The results of our analysis are reported in Table~\ref{tab:accuracy}. For our analysis, we report values of accuracy, one of the most commonly used metric to compare performance, as well as precision and recall of the classes of interest: 'stressed', 'not focused', and 'not awake'. Since the imbalance in the data can lead to high accuracy values if a classifier always just predicts the most likely/frequent class while ignoring the class of higher importance and interest, precision and recall of the class of interest can be more adequate metrics in this case~\cite{yap2014,bhattacharyya_data_2011,Hernandez11}. 
% However, the imbalance in the data can lead to a classifier with high accuracy if it always just predicts the more likely class while ignoring the class of higher importance and interest in our case (i.e. stressed, not focused, not awake). Therefore, we further report the precision and recall for the three classes 'stressed', 'not focused' and 'not awake'. 



Overall, we were able to use the extracted physiological features to predict all three aspects with reasonable accuracy, precision, and recall, as well as to improve upon the baseline---a stratified random classifier that randomly chooses one of the two classes with a bias towards the larger class. While the individually trained classifiers improved on average across all participants upon the baseline in all cases excepting recall of 'not focused', the improvement was substantially higher for awakeness (85\% improvement in precision,  62\% in recall, and 7\% in accuracy) than for stress or focus. Also, the performance of the individually trained classifiers varied greatly across participants. While some participants showed a large improvement, for others the baseline performed much better than the individually trained classifier. For instance, for predicting 'stressed', the individual classifiers improved upon the baseline for S4, S6, S8, S11, S12, and S14 with a maximum improvement of 88.4\% in precision and 184.6\% in recall for S12, while they did worse for S1, S3, S5, S7, S9, S10, and S13, and in the worst cases did not correctly predict a single instance of 'stressed'. Typically users that have the lowest precision and recall values are those where the data is the most unbalanced. This translates to a scenario where the classifier will likely label the minority instances as part of the majority class due to the unbalanced ratio of the data.\\[-0.1cm]
% We attribute these discrepancies to the large differences in response distributions between participants, as well as to the subjectivity of self-reporting.
%
%(improvement: 8\% precision, 1\% recall, 8\% accuracy), the individual performance varied greatly among participants. Some participants showed negligible difference in comparison to the baseline classifier, e.g. subject ..., while others showed a large improvement, e.g. subject ...
%\begin{table}[h!]
%\begin{centering}
%\begin{tabular}{lll}
%\hline
%Participant & Recall Improvement (\%) & Precision Improvement (\%)\\
%\hline
%S12 & 184.6 & 88.4 \\
%S6 & 66.7 & 85.8 \\
%S11 & 50.0 & 44.4 \\
%S8 & 32.4 & 26.7 \\
%S14 & 14.7 & 9.8 \\
%S4 & 5.6 & 5.5 \\
%S9 & -55.4 & -46.8 \\
%S3 & -90.0 & -82.1 \\
%S1 & -100.0 & -100.0 \\
%S5 & -100.0 & -100.0 \\
%S7 & -100.0 & -100.0 \\
%S10 & -100.0 & -100.0 \\
%S13 & -100.0 & -100.0\\
%S2 & - & -\\
%\hline
%\end{tabular}
%\caption{Percentage improvement in recall and precision for stress, using our approach compared to the baseline, on an individual level. For participant 2, the baseline achieved a precision and recall of 0, thus the improvement is undefined}
%\end{centering}
%\label{tab:indImprovement}
%\end{table}



\noindent\textit{Feature Selection and Importance}\\
There are a large variety of features that can be (and have been) calculated in previous research for each of the basic measurements listed in Table~\ref{signals}, such as the mean, standard deviation, maximum, and interquartile range. In addition, each of these metrics can be combined with the various time windows captured of a basic measurement, resulting in a large feature space. To reduce the feature space, we experimented with multiple feature selection methods, including selecting the top k highest correlated features by various metrics such as mutual information, Pearson's correlation coefficient, ANOVA's F-value, as well as wrapper methods such as recursive feature elimination, optimizing mean decrease accuracy by iteratively permuting features, and only selecting features that exceed a certain Gini importance threshold. We found that all methods produced similar results with respect to accuracy, precision, and recall for the individual models. Ultimately, we chose to use the top k features with the highest ANOVA F-value, as it is relatively simple and efficient to calculate. The values of k used were selected by grid search analysis, and are shown in Table \ref{tab:hyperparams}. 

%Respiration rate is also highly important for stress (#3 , 14.4%) but I'm not sure what previous works say about correlation with stress
Overall, the features that were selected as the important ones for the individual models based on the random forest algorithm varied greatly across participants. Yet, some feature categories were considered to be important more frequently than others. Table~\ref{tab:featureImportance} shows the averaged Gini importance for the feature categories used for predicting stress. Particularly important for stress were the feature categories heart rate variability (18.3\%) and skin temperature (15.7\%), both of which have been shown in several previous studies to be  indicators for stress~\cite{dishman2000stress,mcduff16,kataoka00}. For predicting focus, the feature categories for blood pulse wave (14.2\%) and heart rate variability (13\%) showed to be the most important categories, while for awakeness the most important ones were heart rate variability (13.6\%) and blood pulse wave (13.1\%).\\[-0.1cm]


\begin{table}[h!]
  \begin{centering}
  \begin{tabular}{llll}
    \hline
    Feature Category & Stress & Focus & Awakeness\\
    \hline
    Heart Rate Variability & 18.3\% & 13\% & 13.6\%\\
    Blood Pulse Wave & 10\% & 14.2\% & 13.1\%\\
    Heart Rate & 8.7\% & 12.6\% & 10.3\%\\
    Skin Temperature & 15.7\% & 9.8\% & 10\%\\
    Galvanic Skin Response & 6.6\% & 8.2\% & 5.1\%\\
    Respiration Rate & 14.8\% & 12.7\% & 10\%\\
    Oxygen Saturation & 5.6\% & 4.3\% & 2\%\\ 
    Energy Expenditure & 6\% & 7.7\% & 4.8\%\\
    Activity & 4.6\% & 7.8\% & 7.6\%\\
    Steps & 1.7\% & 0.8\% & 0.9\%\\
    Time of Day & 0\% & 0.1\% & 0.5\%\\
    \hline
  \end{tabular}
  \caption{The averaged Gini importance of each feature category, per response variable.}
  \label{tab:featureImportance}
  \end{centering}
  \vspace*{-2mm}
\end{table}


\noindent\textit{Individual vs.\ General Model}\\
Individual models are trained specifically for each individual and thus require a data collection period before they are capable of making accurate predictions. On the other hand, the idea of general models is to be able to train them on already collected data and then  to be able to apply them even to new and unseen individuals, thus overcoming the cold-start problem. Given the big individual differences in biometrics, training a general model to achieve an adequate accuracy for new individuals is not necessarily possible. 

To examine the performance of a general model for our participants, we trained three general models, one for focus, one for awakeness and one for stress. We roughly followed the same procedure as for the individual models. Due to the larger amount of data available in the general case, we used the more common random undersampling, which randomly selects elements in the majority class to exclude from the dataset, instead of random oversampling to balance the distribution of the dataset. The models were trained on the datasets of 13 of the 14 participants, and then evaluated on the dataset of the last, repeating this process for all 14 participants. 

The bottom row of Table \ref{tab:accuracy} presents the averaged performance results for this approach in terms of accuracy, precision, and recall. Although the averaged precision and recall are comparable or better than those of the averaged individual results, this was at the cost of a large decrease in overall accuracy. Upon closer investigation into the performance of the general model when testing on each participant, we found that individually trained models for each participant performed much better than a general model trained over all participants. Using stress as an example, for participant S12, for whom we saw the greatest increase compared to the baseline in individual models, the general model was unable to predict a single instance of 'stressed' correctly. This is consistent with our expectations because biometric features are highly specific to individuals.


%\todo{put the content of the following sentence somewhere into the discussion; We attribute these discrepancies to the large differences in response distributions between participants, as well as to the subjectivity of self-reporting.}

